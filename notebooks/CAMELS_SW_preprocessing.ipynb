{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T15:21:14.380782Z",
     "start_time": "2024-11-07T15:20:36.091024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "# Define paths to the CSV folder and shapefile\n",
    "folder_path = \"N:/gebhyd/3_Hyv/Diplomanden/2_Running/L_Nuesch/data_sweden/CAMELS_SW/2023-173-1/data/catchment time series/catchment_time_series\"\n",
    "shapefile_path = \"N:/gebhyd/3_Hyv/Diplomanden/2_Running/L_Nuesch/data_sweden/CAMELS_SW/2023-173-1/data/catchment_GIS_shapefiles/catchment_GIS_shapefiles/Sweden_catchments_50_stations_WGS84.shp\"\n",
    "\n",
    "# Load the shapefile and extract lon, lat, and Station_ID\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "gdf = gdf.set_geometry('geometry')\n",
    "\n",
    "# Extract lon and lat from the geometry\n",
    "gdf['lon'] = gdf.geometry.x\n",
    "gdf['lat'] = gdf.geometry.y\n",
    "\n",
    "# Keep only relevant columns: Station_ID, lon, and lat\n",
    "station_info = gdf[['id', 'lon', 'lat']].set_index('id')\n",
    "# Convert both to strings\n",
    "station_info.index = station_info.index.astype(str)\n",
    "dataset['Station_ID'] = dataset['Station_ID'].astype(str)\n",
    "\n",
    "# Initialize a list to hold each station's data as a DataArray\n",
    "data_arrays = []\n",
    "\n",
    "# Loop through each CSV file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Extract Station_ID from the file name (assuming it follows a specific pattern)\n",
    "        station_id = file_name.split('_')[2].split('.')[0]  # Adjust the index if necessary\n",
    "\n",
    "        # Load the CSV file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Combine Year, Month, and Day columns into a datetime column\n",
    "        df['time'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
    "\n",
    "        # Set the 'time' as the index and drop Year, Month, and Day columns\n",
    "        df = df.set_index('time').drop(columns=['Year', 'Month', 'Day'])\n",
    "\n",
    "        # Convert the DataFrame to an xarray DataArray for each station\n",
    "        data_array = xr.DataArray(\n",
    "            data=df.values,\n",
    "            dims=['time', 'variable'],\n",
    "            coords={\n",
    "                'time': df.index,  # time coordinate\n",
    "                'variable': df.columns,  # each column as a variable\n",
    "                'Station_ID': station_id  # each file provides one station's data\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Append the DataArray for this station to the list\n",
    "        data_arrays.append(data_array)\n",
    "\n",
    "# Concatenate all station DataArrays along the 'Station_ID' dimension\n",
    "dataset = xr.concat(data_arrays, dim='Station_ID')\n",
    "\n",
    "# Convert DataArray to Dataset, setting each column as a separate variable\n",
    "dataset = dataset.to_dataset(dim='variable')\n",
    "\n",
    "# Add lon and lat as coordinates from the station_info DataFrame\n",
    "lon_values = station_info.reindex(dataset['Station_ID'].values)['lon'].values\n",
    "lat_values = station_info.reindex(dataset['Station_ID'].values)['lat'].values\n",
    "dataset = dataset.assign_coords(lon=('Station_ID', lon_values), lat=('Station_ID', lat_values))\n",
    "\n",
    "# Rename variables from \"variable\" dimension values to actual column names\n",
    "for var in dataset.data_vars:\n",
    "    dataset[var].attrs['long_name'] = var\n",
    "\n",
    "# Save the dataset to a NetCDF file (optional)\n",
    "print(dataset)\n",
    "# Save the dataset to a NetCDF file (optional)\n",
    "#dataset.to_netcdf('output_dataset.nc')\n"
   ],
   "id": "becef1e637cdc38e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:     (Station_ID: 50, time: 21915)\n",
      "Coordinates:\n",
      "  * time        (time) datetime64[ns] 1961-01-01 1961-01-02 ... 2020-12-31\n",
      "  * Station_ID  (Station_ID) object '1069' '1083' '1123' ... '751' '855' '97'\n",
      "    lon         (Station_ID) float64 14.13 12.13 21.81 ... 11.54 16.16 15.71\n",
      "    lat         (Station_ID) float64 56.66 62.64 66.17 ... 58.88 57.01 62.82\n",
      "Data variables:\n",
      "    Qobs_m3s    (Station_ID, time) float64 27.0 27.0 28.0 ... 17.9 18.0 18.2\n",
      "    Qobs_mm     (Station_ID, time) float64 2.274 2.274 2.358 ... 0.7188 0.7268\n",
      "    Pobs_mm     (Station_ID, time) float64 2.081 0.3805 7.043 ... 5.704 9.268\n",
      "    Tobs_C      (Station_ID, time) float64 -0.5748 0.7144 ... -2.064 -3.794\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T15:23:54.574275Z",
     "start_time": "2024-11-07T15:23:54.516354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#streamflow\n",
    "Q_Camels_SW = dataset.copy()\n",
    "Q_Camels_SW = Q_Camels_SW.drop_vars(['Pobs_mm', 'Qobs_mm', 'Tobs_C'])\n",
    "Q_Camels_SW = Q_Camels_SW.rename({\"Qobs_m3s\": \"Flow\"})\n",
    "\n",
    "print(Q_Camels_SW)\n",
    "\n",
    "Q_Camels_SW.to_netcdf('../CAMELS_SW/input_data/Q_Camels_SW.nc')"
   ],
   "id": "e565893fafcebe77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:     (Station_ID: 50, time: 21915)\n",
      "Coordinates:\n",
      "  * time        (time) datetime64[ns] 1961-01-01 1961-01-02 ... 2020-12-31\n",
      "  * Station_ID  (Station_ID) object '1069' '1083' '1123' ... '751' '855' '97'\n",
      "    lon         (Station_ID) float64 14.13 12.13 21.81 ... 11.54 16.16 15.71\n",
      "    lat         (Station_ID) float64 56.66 62.64 66.17 ... 58.88 57.01 62.82\n",
      "Data variables:\n",
      "    Flow        (Station_ID, time) float64 27.0 27.0 28.0 ... 17.9 18.0 18.2\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T15:49:49.187919Z",
     "start_time": "2024-11-07T15:49:49.118425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#precipitation\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "P_Camels_SW = dataset.copy()\n",
    "P_Camels_SW = P_Camels_SW.drop_vars(['Qobs_m3s', 'Qobs_mm', 'Tobs_C'])\n",
    "\n",
    "\n",
    "# Load the elevation data from the CSV file\n",
    "elevation_data = pd.read_csv('N:/gebhyd/3_Hyv/Diplomanden/2_Running/L_Nuesch/data_sweden/CAMELS_SW/2023-173-1/data/catchment properties/catchment properties/catchments_physical_properties.csv')\n",
    "\n",
    "# Rename columns for clarity (assuming 'ID' is the station identifier and 'Elevation_mabsl' is the elevation)\n",
    "elevation_data = elevation_data.rename(columns={'ID': 'Station_ID', 'Elevation_mabsl': 'elevation'})\n",
    "\n",
    "# Set Station_ID as the index for easy alignment\n",
    "elevation_data = elevation_data.set_index('Station_ID')\n",
    "\n",
    "# Ensure Station_ID is treated as a string to match the xarray dataset\n",
    "elevation_data.index = elevation_data.index.astype(str)\n",
    "P_Camels_SW['Station_ID'] = P_Camels_SW['Station_ID'].astype(str)\n",
    "\n",
    "# Retrieve the elevation values, matching them to the Station_IDs in the xarray dataset\n",
    "elevation_values = elevation_data.reindex(P_Camels_SW['Station_ID'].values)['elevation'].values\n",
    "\n",
    "# Add elevation as a new coordinate in the dataset\n",
    "P_Camels_SW = P_Camels_SW.assign_coords(elevation=('Station_ID', elevation_values))\n",
    "\n",
    "# Step 1: Extract the longitude, latitude, and elevation as arrays\n",
    "lon_values = P_Camels_SW['lon'].values\n",
    "lat_values = P_Camels_SW['lat'].values\n",
    "elevation_values = P_Camels_SW['elevation'].values\n",
    "\n",
    "# Step 2: Create a new variable 'LLE' with dimension 'lle' (lon, lat, elevation)\n",
    "lle_data = xr.DataArray(\n",
    "    data=[lon_values, lat_values, elevation_values],\n",
    "    dims=[\"lle\", \"Station_ID\"],  # Use \"Station_ID\" as the dimension name\n",
    "    coords={\"lle\": [\"lon\", \"lat\", \"elev\"], \"Station_ID\": P_Camels_SW[\"Station_ID\"].values}\n",
    ")\n",
    "\n",
    "# Step 3: Rename 'Station_ID' to 'station' and 'time' to 'nday' to match the target structure\n",
    "P_Camels_SW = P_Camels_SW.rename({\"time\": \"nday\"})\n",
    "\n",
    "# Step 4: Add 'LLE' as a data variable instead of a coordinate\n",
    "P_Camels_SW['LLE'] = lle_data\n",
    "\n",
    "# Step 5: Drop the original 'lon', 'lat', and 'elevation' coordinates\n",
    "P_Camels_SW = P_Camels_SW.drop_vars(['lon', 'lat', 'elevation'])\n",
    "\n",
    "# Step 6: Rename the main data variable if necessary\n",
    "P_Camels_SW = P_Camels_SW.rename({\"Pobs_mm\": \"precipitation\"})\n",
    "P_Camels_SW = P_Camels_SW.rename({\"Station_ID\": \"station\"})\n",
    "# Check the final structure of the transformed dataset\n",
    "P_Camels_SW['LLE'] = P_Camels_SW['LLE'].transpose('station', 'lle')\n",
    "print(P_Camels_SW)\n",
    "\n",
    "P_Camels_SW.to_netcdf('../CAMELS_SW/input_data/P_Camels_SW.nc')"
   ],
   "id": "3f4b57657ee6e5c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:        (lle: 3, nday: 21915, station: 50)\n",
      "Coordinates:\n",
      "  * nday           (nday) datetime64[ns] 1961-01-01 1961-01-02 ... 2020-12-31\n",
      "  * station        (station) <U5 '1069' '1083' '1123' ... '751' '855' '97'\n",
      "  * lle            (lle) <U4 'lon' 'lat' 'elev'\n",
      "Data variables:\n",
      "    precipitation  (station, nday) float64 2.081 0.3805 7.043 ... 5.704 9.268\n",
      "    LLE            (station, lle) float64 14.13 56.66 165.7 ... 62.82 365.6\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4e964155aa2eba0d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
